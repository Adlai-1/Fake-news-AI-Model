{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as num\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#Libraries that check the accuracy of the model over test set\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to Determine the Proper directory to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./FN_Model.h5\n",
      "./Model.ipynb\n",
      "./.git\\COMMIT_EDITMSG\n",
      "./.git\\config\n",
      "./.git\\description\n",
      "./.git\\HEAD\n",
      "./.git\\index\n",
      "./.git\\hooks\\applypatch-msg.sample\n",
      "./.git\\hooks\\commit-msg.sample\n",
      "./.git\\hooks\\fsmonitor-watchman.sample\n",
      "./.git\\hooks\\post-update.sample\n",
      "./.git\\hooks\\pre-applypatch.sample\n",
      "./.git\\hooks\\pre-commit.sample\n",
      "./.git\\hooks\\pre-merge-commit.sample\n",
      "./.git\\hooks\\pre-push.sample\n",
      "./.git\\hooks\\pre-rebase.sample\n",
      "./.git\\hooks\\pre-receive.sample\n",
      "./.git\\hooks\\prepare-commit-msg.sample\n",
      "./.git\\hooks\\push-to-checkout.sample\n",
      "./.git\\hooks\\update.sample\n",
      "./.git\\info\\exclude\n",
      "./.git\\logs\\HEAD\n",
      "./.git\\logs\\refs\\heads\\main\n",
      "./.git\\logs\\refs\\remotes\\origin\\main\n",
      "./.git\\objects\\03\\805733ab6dea2d4666a05bacc81d40fc6e639d\n",
      "./.git\\objects\\0a\\b53fd67cb79705c847fa93d44f501a9d36adb5\n",
      "./.git\\objects\\16\\e2f04fa018fa8f027d6fc3afde6d6e89f7df6e\n",
      "./.git\\objects\\1d\\905edc495e788a78623ff1f1f29c94eb7a6494\n",
      "./.git\\objects\\20\\167fddd811aa4f7b9997c5deb494edd5e9771d\n",
      "./.git\\objects\\45\\128f7b518f6dc52a7c576d2f1f5ac3cb0db99c\n",
      "./.git\\objects\\46\\ea81ae09608580baf913006837a0d6b7860812\n",
      "./.git\\objects\\6a\\01148bc02f1accbb7a1e84a2b4dbcef14f0fbd\n",
      "./.git\\objects\\b7\\0fb4ccc2530aa78dbbc44506dc691422d3f1cf\n",
      "./.git\\objects\\d7\\058b4f5534fdee5620d1503e79237b82917123\n",
      "./.git\\refs\\heads\\main\n",
      "./.git\\refs\\remotes\\origin\\main\n",
      "./Fake\\Fake.csv\n",
      "./True\\True.csv\n",
      "./__pycache__\\Server.cpython-310.pyc\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('./'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening Data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fake_data = pd.read_csv('./Fake/Fake.csv')\n",
    "True_data = pd.read_csv('./True/True.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Clean-up....Begining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fake_data.head(2) #THE initial form in which our data is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fake_data =Fake_data.drop(columns=[\"date\",\"subject\",\"title\"]) #Removing some unwanted columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_data = True_data.drop(columns=[\"date\",\"subject\",\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning Tags for easy differetiation of News types (either Fake or True) True news = 1 and Fake news = 0\n",
    "(i.e. Any value approaching 1 indicates Fake news and any Value approaching 0 indicates True news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_data['fake'] = 1\n",
    "Fake_data['fake'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  fake\n",
       "0  Donald Trump just couldn t wish all Americans ...     0\n",
       "1  House Intelligence Committee Chairman Devin Nu...     0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fake_data.head(2) #Previewing our new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  fake\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...     1\n",
       "1  WASHINGTON (Reuters) - Transgender people will...     1\n",
       "2  WASHINGTON (Reuters) - The special counsel inv...     1\n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...     1\n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23481, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fake_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21417, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"My name is David Adlai Nettey. I do Computer Science\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = np.word_tokenize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'is', 'David', 'Adlai', 'Nettey', '.', 'I', 'do', 'Computer', 'Science']\n"
     ]
    }
   ],
   "source": [
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = Fake_data['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = trial.lower() # Converting from uppercase to lowercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house intelligence committee chairman devin nunes is going to have a bad day. he s been under the assumption, like many of us, that the christopher steele-dossier was what prompted the russia investigation so he s been lashing out at the department of justice and the fbi in order to protect trump. as it happens, the dossier is not what started the investigation, according to documents obtained by the new york times.former trump campaign adviser george papadopoulos was drunk in a wine bar when he revealed knowledge of russian opposition research on hillary clinton.on top of that, papadopoulos wasn t just a covfefe boy for trump, as his administration has alleged. he had a much larger role, but none so damning as being a drunken fool in a wine bar. coffee boys  don t help to arrange a new york meeting between trump and president abdel fattah el-sisi of egypt two months before the election. it was known before that the former aide set up meetings with world leaders for trump, but team trump ran with him being merely a coffee boy.in may 2016, papadopoulos revealed to australian diplomat alexander downer that russian officials were shopping around possible dirt on then-democratic presidential nominee hillary clinton. exactly how much mr. papadopoulos said that night at the kensington wine rooms with the australian, alexander downer, is unclear,  the report states.  but two months later, when leaked democratic emails began appearing online, australian officials passed the information about mr. papadopoulos to their american counterparts, according to four current and former american and foreign officials with direct knowledge of the australians  role. papadopoulos pleaded guilty to lying to the f.b.i. and is now a cooperating witness with special counsel robert mueller s team.this isn t a presidency. it s a badly scripted reality tv show.photo by win mcnamee/getty images.\n"
     ]
    }
   ],
   "source": [
    "print(trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function necessary for cleaning our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):  #Removing any kind of punctuation present in the data\n",
    "    return re.sub(r'[^\\w\\s]','', str(text))\n",
    "\n",
    "def remove_urls(text):  #Removing urls from the data\n",
    "    return re.sub(r\"http\\S+\", \"\", str(text))\n",
    "                  \n",
    "def remove_stopwords(text):  #Removing stopwords(eg. this, that, am, be etc)\n",
    "    stop = stopwords.words(\"english\")\n",
    "    final_text = []\n",
    "    for i in str(text).split():\n",
    "        if i.strip() not in stop:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "                  \n",
    "def tokenize(text):  \n",
    "    tokens = re.split('\\W+',text) #W+ means that either a word character (A-Z) or a dash(-) can go there.\n",
    "    return tokens\n",
    "\n",
    "def tokenize_words(text):  #Converting all the text to lower case\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "                                  \n",
    "def stemming(text):  #Converting the words into their stem form\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    return porter_stemmer.stem(str(text))\n",
    "                  \n",
    "def lemmatization(text):  #Applying Lemaatization i.e., converting words into their lemma\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    return wordnet_lemmatizer.lemmatize(str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that executes our data cleaning...\n",
    "def clean_text(text):\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_urls(text)\n",
    "    text = tokenize_words(text)\n",
    "    text = stemming(text)\n",
    "    return lemmatization(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_data['text'] = True_data['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fake_data['text'] = Fake_data['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['donald', 'trump', 'wish', 'americans', 'happy', 'new', 'year', 'leave', 'that', 'instead', 'give', 'shout', 'enemies', 'haters', 'dishonest', 'fake', 'news', 'media', 'the', 'former', 'reality', 'show', 'star', 'one', 'job', 'it', 'as', 'country', 'rapidly', 'grows', 'stronger', 'smarter', 'i', 'want', 'wish', 'friends', 'supporters', 'enemies', 'haters', 'even', 'dishonest', 'fake', 'news', 'media', 'happy', 'healthy', 'new', 'year', 'president', 'angry', 'pants', 'tweeted', '2018', 'great', 'year', 'america', 'as', 'country', 'rapidly', 'grows', 'stronger', 'smarter', 'i', 'want', 'wish', 'friends', 'supporters', 'enemies', 'haters', 'even', 'dishonest', 'fake', 'news', 'media', 'happy', 'healthy', 'new', 'year', '2018', 'great', 'year', 'america', 'donald', 'j', 'trump', 'realdonaldtrump', 'december', '31', '2017trump', 'tweet', 'went', 'welll', 'expectwhat', 'kind', 'president', 'sends', 'new', 'year', 'greeting', 'like', 'despicable', 'petty', 'infantile', 'gibberish', 'only', 'trump', 'his', 'lack', 'decency', 'even', 'allow', 'rise', 'gutter', 'long', 'enough', 'wish', 'american', 'citizens', 'happy', 'new', 'year', 'bishop', 'talbert', 'swan', 'talbertswan', 'december', '31', '2017no', 'one', 'likes', 'calvin', 'calvinstowell', 'december', '31', '2017your', 'impeachment', 'would', 'make', '2018', 'great', 'year', 'america', 'i', 'also', 'accept', 'regaining', 'control', 'congress', 'miranda', 'yaver', 'mirandayaver', 'december', '31', '2017do', 'hear', 'talk', 'when', 'include', 'many', 'people', 'hate', 'wonder', 'why', 'hate', 'me', 'alan', 'sandoval', 'alansandoval13', 'december', '31', '2017who', 'uses', 'word', 'haters', 'new', 'years', 'wish', 'marlene', 'marlene399', 'december', '31', '2017you', 'say', 'happy', 'new', 'year', 'koren', 'pollitt', 'korencarpenter', 'december', '31', '2017here', 'trump', 'new', 'year', 'eve', 'tweet', '2016happy', 'new', 'year', 'all', 'including', 'many', 'enemies', 'fought', 'lost', 'badly', 'know', 'do', 'love', 'donald', 'j', 'trump', 'realdonaldtrump', 'december', '31', '2016this', 'nothing', 'new', 'trump', 'he', 'yearstrump', 'directed', 'messages', 'enemies', 'haters', 'new', 'year', 's', 'easter', 'thanksgiving', 'anniversary', '911', 'pictwittercom4fpae2kypa', 'daniel', 'dale', 'ddale8', 'december', '31', '2017trump', 'holiday', 'tweets', 'clearly', 'presidentialhow', 'long', 'work', 'hallmark', 'becoming', 'president', 'steven', 'goodine', 'sgoodine', 'december', '31', '2017he', 'always', 'like', 'difference', 'last', 'years', 'filter', 'breaking', 'down', 'roy', 'schulze', 'thbthttt', 'december', '31', '2017who', 'apart', 'teenager', 'uses', 'term', 'haters', 'wendy', 'wendywhistles', 'december', '31', '2017he', 'fucking', '5', 'year', 'old', 'who', 'knows', 'rainyday80', 'december', '31', '2017so', 'people', 'voted', 'hole', 'thinking', 'would', 'change', 'got', 'power', 'wrong', '70yearold', 'men', 'change', 'year', 'olderphoto', 'andrew', 'burtongetty', 'images']\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fake_data['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining both fake and true news to form one Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "News_data = pd.concat([True_data,Fake_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44898, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "News_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23479</th>\n",
       "      <td>['21st', 'century', 'wire', 'says', 'al', 'jaz...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23480</th>\n",
       "      <td>['21st', 'century', 'wire', 'says', 'as', '21w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  fake\n",
       "23479  ['21st', 'century', 'wire', 'says', 'al', 'jaz...     0\n",
       "23480  ['21st', 'century', 'wire', 'says', 'as', '21w...     0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "News_data.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "News_data = shuffle(News_data,random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Clean-up...Completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test =  train_test_split(News_data['text'],News_data['fake'],test_size=0.20,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35918,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the words into vectors because we can only give numerical data as input to the model\n",
    "max_vocab = 5000\n",
    "tokenizer = Tokenizer(num_words = max_vocab)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "#Padding is applied so that we get the same length of input for each article\n",
    "\n",
    "x_train = pad_sequences(x_train, padding = \"post\", maxlen = 25)\n",
    "x_test = pad_sequences(x_test, padding = \"post\", maxlen = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35918, 25)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_features = 256\n",
    "model=tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(5000, embedding_vector_features, input_length=25))\n",
    "model.add(tf.keras.layers.SpatialDropout1D(0.2))\n",
    "model.add(tf.keras.layers.LSTM(64, dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(100, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adagrad', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 256)           1280000   \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 25, 256)          0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                82176     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,368,777\n",
      "Trainable params: 1,368,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1078/1078 [==============================] - 61s 52ms/step - loss: 0.6888 - accuracy: 0.5490 - val_loss: 0.6854 - val_accuracy: 0.5354\n",
      "Epoch 2/6\n",
      "1078/1078 [==============================] - 54s 50ms/step - loss: 0.6830 - accuracy: 0.5579 - val_loss: 0.6789 - val_accuracy: 0.5649\n",
      "Epoch 3/6\n",
      "1078/1078 [==============================] - 53s 49ms/step - loss: 0.6755 - accuracy: 0.5963 - val_loss: 0.6693 - val_accuracy: 0.6269\n",
      "Epoch 4/6\n",
      "1078/1078 [==============================] - 54s 50ms/step - loss: 0.6637 - accuracy: 0.6750 - val_loss: 0.6539 - val_accuracy: 0.7266\n",
      "Epoch 5/6\n",
      "1078/1078 [==============================] - 55s 51ms/step - loss: 0.6447 - accuracy: 0.7579 - val_loss: 0.6283 - val_accuracy: 0.8238\n",
      "Epoch 6/6\n",
      "1078/1078 [==============================] - 54s 50ms/step - loss: 0.6120 - accuracy: 0.8164 - val_loss: 0.5842 - val_accuracy: 0.8402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c7145f4f70>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 6, validation_split = 0.10, batch_size = 30, shuffle = True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 2s 8ms/step - loss: 0.5851 - accuracy: 0.8404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5851209759712219, 0.8404231667518616]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Accuracy after testing on unseen data is 84.04%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our Model Prediction, 1 == Fake news and 0 == Factual news. eg: if the model predicts 80% it definately means Fake news and if the model predicts 20% its definately Factual news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5352786 ]\n",
      " [0.52618843]\n",
      " [0.5328309 ]\n",
      " ...\n",
      " [0.3464765 ]\n",
      " [0.5159141 ]\n",
      " [0.5157778 ]]\n"
     ]
    }
   ],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_preperation(news:str):\n",
    "    news = clean_text(news)\n",
    "    tokenizer.fit_on_texts(news)\n",
    "    news = tokenizer.texts_to_sequences(news)\n",
    "    news = pad_sequences(news, padding= \"post\", maxlen = 25)\n",
    "    results = model.predict(news)\n",
    "    result = results[0]\n",
    "    return \"{:.2f}\".format(result[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake news Probability: 82.62 True News Probability: 17.38\n"
     ]
    }
   ],
   "source": [
    "res = news_preperation(\"There is a War in Ukraine\")\n",
    "res = float(res)\n",
    "true = res\n",
    "false = 100.00 - res\n",
    "false = \"{:.2f}\".format(false)\n",
    "print(\"Fake news Probability: \"+ str(false) + \" True News Probability: \"+ str(true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the AI Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading our Saved Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fmodel = tf.keras.models.load_model(\"Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 2s 9ms/step - loss: 0.5851 - accuracy: 0.8404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5851209759712219, 0.8404231667518616]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fmodel.evaluate(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dfd77b68dc4ed90f94666cbf3510ba4a67ed5186df015e0ded04a2a4e378969c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
